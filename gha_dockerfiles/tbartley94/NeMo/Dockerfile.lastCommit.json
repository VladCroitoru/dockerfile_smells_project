[{"sha":"a48be1f2679198905f650e05cc93104a9dda4ec6","node_id":"C_kwDOGIUfR9oAKGE0OGJlMWYyNjc5MTk4OTA1ZjY1MGUwNWNjOTMxMDRhOWRkYTRlYzY","commit":{"author":{"name":"Eric Harper","email":"complex451@gmail.com","date":"2021-11-12T06:25:47Z"},"committer":{"name":"GitHub","email":"noreply@github.com","date":"2021-11-12T06:25:47Z"},"message":"Merge r1.5.0 bugfixes to main (#3173)\n\n* update branch\r\n\r\nSigned-off-by: ericharper <complex451@gmail.com>\r\n\r\n* Always save last checkpoint on train end even if folder does not exist (#2976)\r\n\r\n* add fix for no checkpoint folder when training ends\r\n\r\nSigned-off-by: Jason <jasoli@nvidia.com>\r\n\r\n* update\r\n\r\nSigned-off-by: Jason <jasoli@nvidia.com>\r\n\r\n* fix test\r\n\r\nSigned-off-by: Jason <jasoli@nvidia.com>\r\n\r\n* fixes\r\n\r\nSigned-off-by: Jason <jasoli@nvidia.com>\r\n\r\n* typo\r\n\r\nSigned-off-by: Jason <jasoli@nvidia.com>\r\n\r\n* change check\r\n\r\nSigned-off-by: Jason <jasoli@nvidia.com>\r\n\r\n* [NLP] Add Apex import guard (#3041)\r\n\r\n* add apex import guard\r\n\r\nSigned-off-by: ericharper <complex451@gmail.com>\r\n\r\n* add apex import guard\r\n\r\nSigned-off-by: ericharper <complex451@gmail.com>\r\n\r\n* add apex import guard\r\n\r\nSigned-off-by: ericharper <complex451@gmail.com>\r\n\r\n* style\r\n\r\nSigned-off-by: ericharper <complex451@gmail.com>\r\n\r\n* remove from init add logging to constructor\r\n\r\nSigned-off-by: ericharper <complex451@gmail.com>\r\n\r\n* remove from init add logging to constructor\r\n\r\nSigned-off-by: ericharper <complex451@gmail.com>\r\n\r\n* remove import from init\r\n\r\nSigned-off-by: ericharper <complex451@gmail.com>\r\n\r\n* remove megatron bert encoder logic from NLPModel\r\n\r\nSigned-off-by: ericharper <complex451@gmail.com>\r\n\r\n* remove megatron bert from init\r\n\r\nSigned-off-by: ericharper <complex451@gmail.com>\r\n\r\n* remove megatron bert from init\r\n\r\nSigned-off-by: ericharper <complex451@gmail.com>\r\n\r\n* remove megatron bert from init\r\n\r\nSigned-off-by: ericharper <complex451@gmail.com>\r\n\r\n* remove megatron bert from init\r\n\r\nSigned-off-by: ericharper <complex451@gmail.com>\r\n\r\n* remove megatron bert from init\r\n\r\nSigned-off-by: ericharper <complex451@gmail.com>\r\n\r\n* remove megatron bert from init\r\n\r\nSigned-off-by: ericharper <complex451@gmail.com>\r\n\r\n* style\r\n\r\nSigned-off-by: ericharper <complex451@gmail.com>\r\n\r\n* Update reinstall and cherry-pick bignlp commits (#3065)\r\n\r\n* add ptl install to reinstall and update jenkins install\r\n\r\nSigned-off-by: ericharper <complex451@gmail.com>\r\n\r\n* Add a stateless timer to specify max_time per run instead of global m… (#3056)\r\n\r\n* Add a stateless timer to specify max_time per run instead of global max_time across runs\r\n\r\nSigned-off-by: MaximumEntropy <sandeep.subramanian.1@umontreal.ca>\r\n\r\n* Style fixes\r\n\r\nSigned-off-by: MaximumEntropy <sandeep.subramanian.1@umontreal.ca>\r\n\r\n* (1) reduce the validation loss within a epoch, (2) convert global-batch-based iteartion counts to micro-batch-based (#3055)\r\n\r\nCo-authored-by: Oleksii Kuchaiev <okuchaiev@users.noreply.github.com>\r\n\r\n* Timer class monitors total time (train + validation + testing) to monitor when to end training (#3061)\r\n\r\n* Check total time in train/validation to exit\r\n\r\nSigned-off-by: MaximumEntropy <sandeep.subramanian.1@umontreal.ca>\r\n\r\n* Style fixes\r\n\r\nSigned-off-by: MaximumEntropy <sandeep.subramanian.1@umontreal.ca>\r\n\r\nCo-authored-by: Oleksii Kuchaiev <okuchaiev@users.noreply.github.com>\r\n\r\n* Add PUBLICATIONS.md (#3051)\r\n\r\n* Add PUBLICATIONS.md\r\n\r\nSigned-off-by: smajumdar <titu1994@gmail.com>\r\n\r\n* Add NLP\r\n\r\nSigned-off-by: smajumdar <titu1994@gmail.com>\r\n\r\n* Update PUBLICATIONS.md\r\n\r\n* Update PUBLICATIONS.md\r\n\r\n* Fix links\r\n\r\nSigned-off-by: smajumdar <titu1994@gmail.com>\r\n\r\nCo-authored-by: Eric Harper <complex451@gmail.com>\r\n\r\n* fix uninstall\r\n\r\nSigned-off-by: ericharper <complex451@gmail.com>\r\n\r\nCo-authored-by: Sandeep Subramanian <sandeep.subramanian.1@umontreal.ca>\r\nCo-authored-by: Sangkug Lym <slym@nvidia.com>\r\nCo-authored-by: Oleksii Kuchaiev <okuchaiev@users.noreply.github.com>\r\nCo-authored-by: Somshubra Majumdar <titu1994@gmail.com>\r\n\r\n* fix File Load Error (#3069)\r\n\r\nSigned-off-by: fayejf <fayejf07@gmail.com>\r\n\r\nCo-authored-by: Eric Harper <complex451@gmail.com>\r\n\r\n* Exp manager small refactor (#3067)\r\n\r\n* Exp manager small refactor\r\n\r\nSigned-off-by: MaximumEntropy <sandeep.subramanian.1@umontreal.ca>\r\n\r\n* move super() call earlier in the function\r\n\r\nSigned-off-by: MaximumEntropy <sandeep.subramanian.1@umontreal.ca>\r\n\r\nCo-authored-by: Somshubra Majumdar <titu1994@gmail.com>\r\n\r\n* update (#3113)\r\n\r\nSigned-off-by: Jason <jasoli@nvidia.com>\r\n\r\n* Upgrade to PTL 1.5.0 (#3127)\r\n\r\n* update for ptl 1.5.0\r\n\r\nSigned-off-by: ericharper <complex451@gmail.com>\r\n\r\n* update trainer config\r\n\r\nSigned-off-by: ericharper <complex451@gmail.com>\r\n\r\n* limit cuda visible devices to the first two gpus on check for ranks CI test\r\n\r\nSigned-off-by: ericharper <complex451@gmail.com>\r\n\r\n* remove comments\r\n\r\nSigned-off-by: ericharper <complex451@gmail.com>\r\n\r\n* make datasets larger for test\r\n\r\nSigned-off-by: ericharper <complex451@gmail.com>\r\n\r\n* make datasets larger for test\r\n\r\nSigned-off-by: ericharper <complex451@gmail.com>\r\n\r\n* update compute_max_steps\r\n\r\nSigned-off-by: ericharper <complex451@gmail.com>\r\n\r\n* update compute_max_steps\r\n\r\nSigned-off-by: ericharper <complex451@gmail.com>\r\n\r\n* Update a few packages' version (#3134)\r\n\r\n* update torchaudio lower bound in tutorials\r\n\r\nSigned-off-by: fayejf <fayejf07@gmail.com>\r\n\r\n* update torchtext version in tutorials\r\n\r\nSigned-off-by: fayejf <fayejf07@gmail.com>\r\n\r\n* Revert \"update torchtext version in tutorials\"\r\n\r\nThis reverts commit 9f7f660f3b0926d3b7d6cdbb92751e0d881d65f3.\r\n\r\n* update torchtext in tutorials\r\n\r\nSigned-off-by: fayejf <fayejf07@gmail.com>\r\n\r\n* update packages version in this notebook\r\n\r\nSigned-off-by: fayejf <fayejf07@gmail.com>\r\n\r\n* update numba version in tutorial\r\n\r\nSigned-off-by: fayejf <fayejf07@gmail.com>\r\n\r\n* update requirements\r\n\r\nSigned-off-by: fayejf <fayejf07@gmail.com>\r\n\r\n* update package version in Dockerfile\r\n\r\nSigned-off-by: fayejf <fayejf07@gmail.com>\r\n\r\n* Revert \"update torchtext version in tutorials\"\r\n\r\nThis reverts commit 9f7f660f3b0926d3b7d6cdbb92751e0d881d65f3.\r\n\r\nSigned-off-by: fayejf <fayejf07@gmail.com>\r\n\r\n* added to avail models (#3044)\r\n\r\nSigned-off-by: Yang Zhang <yangzhang@nvidia.com>\r\n\r\n* 1. Fixed warmup batches when no timing is measured. (#3140)\r\n\r\nSigned-off-by: Micha Livne <mlivne@nvidia.com>\r\n\r\nCo-authored-by: Micha Livne <mlivne@nvidia.com>\r\nCo-authored-by: Yang Zhang <yzhang123@users.noreply.github.com>\r\n\r\n* Cannot unset both `source_processor` and `target_processor` for NMT model inference. (#3136)\r\n\r\n* Fix processor setting for nmt inference\r\n\r\nSigned-off-by: PeganovAnton <peganoff2@mail.ru>\r\n\r\n* Add ignore option description to argparse\r\n\r\nSigned-off-by: PeganovAnton <peganoff2@mail.ru>\r\n\r\n* Fix typo\r\n\r\nSigned-off-by: PeganovAnton <peganoff2@mail.ru>\r\n\r\nCo-authored-by: Oleksii Kuchaiev <okuchaiev@users.noreply.github.com>\r\nCo-authored-by: Sandeep Subramanian <sandeep.subramanian.1@umontreal.ca>\r\n\r\n* config link fixes (#3148)\r\n\r\nSigned-off-by: nithinraok <nithinrao.koluguri@gmail.com>\r\n\r\n* fix nemo checkpoint converter (#3149)\r\n\r\nSigned-off-by: Yu Yao <yuya@nvidia.com>\r\n\r\nCo-authored-by: Yu Yao <yuya@nvidia.com>\r\nCo-authored-by: Eric Harper <complex451@gmail.com>\r\n\r\n* link fix (#3153)\r\n\r\nSigned-off-by: ekmb <ebakhturina@nvidia.com>\r\n\r\n* remove (#3154)\r\n\r\nSigned-off-by: ekmb <ebakhturina@nvidia.com>\r\n\r\n* [BigNLP] Add CI Tests for Megatron GPT (#3124)\r\n\r\n* add pretrain CI test\r\n\r\nSigned-off-by: ericharper <complex451@gmail.com>\r\n\r\n* update test\r\n\r\nSigned-off-by: ericharper <complex451@gmail.com>\r\n\r\n* update test\r\n\r\nSigned-off-by: ericharper <complex451@gmail.com>\r\n\r\n* update test\r\n\r\nSigned-off-by: ericharper <complex451@gmail.com>\r\n\r\n* add .cpp and Makefile to python package_data\r\n\r\nSigned-off-by: ericharper <complex451@gmail.com>\r\n\r\n* check for local_rank and barrier when compiling helper\r\n\r\nSigned-off-by: ericharper <complex451@gmail.com>\r\n\r\n* check for local_rank and barrier when compiling helper\r\n\r\nSigned-off-by: ericharper <complex451@gmail.com>\r\n\r\n* remove comment\r\n\r\nSigned-off-by: ericharper <complex451@gmail.com>\r\n\r\n* remove comment\r\n\r\nSigned-off-by: ericharper <complex451@gmail.com>\r\n\r\n* add device, have jenkins test use fp16\r\n\r\nSigned-off-by: ericharper <complex451@gmail.com>\r\n\r\n* add device, have jenkins test use fp16\r\n\r\nSigned-off-by: ericharper <complex451@gmail.com>\r\n\r\n* update app_state.local_rank\r\n\r\nSigned-off-by: ericharper <complex451@gmail.com>\r\n\r\n* update config\r\n\r\nSigned-off-by: ericharper <complex451@gmail.com>\r\n\r\n* add configure gradient clipping hook\r\n\r\nSigned-off-by: ericharper <complex451@gmail.com>\r\n\r\n* style\r\n\r\nSigned-off-by: ericharper <complex451@gmail.com>\r\n\r\n* add configure gradient clipping hook\r\n\r\nSigned-off-by: ericharper <complex451@gmail.com>\r\n\r\n* add resume test\r\n\r\nSigned-off-by: ericharper <complex451@gmail.com>\r\n\r\n* add eval\r\n\r\nSigned-off-by: ericharper <complex451@gmail.com>\r\n\r\n* add eval\r\n\r\nSigned-off-by: ericharper <complex451@gmail.com>\r\n\r\n* (1) update auto-casting api, (2) simplifiy precision arguments and remove redundancy (#3142)\r\n\r\nSigned-off-by: Sangkug Lym <slym@nvidia.com>\r\n\r\n* only set jit fusion options if we are in 21.10 container\r\n\r\nSigned-off-by: ericharper <complex451@gmail.com>\r\n\r\n* update arg\r\n\r\nSigned-off-by: ericharper <complex451@gmail.com>\r\n\r\n* update nemo file for eval test\r\n\r\nSigned-off-by: ericharper <complex451@gmail.com>\r\n\r\n* remove unused import\r\n\r\nSigned-off-by: ericharper <complex451@gmail.com>\r\n\r\n* remove unused import\r\n\r\nSigned-off-by: ericharper <complex451@gmail.com>\r\n\r\n* move tests down in the jenkinsfile\r\n\r\nSigned-off-by: ericharper <complex451@gmail.com>\r\n\r\n* style\r\n\r\nSigned-off-by: ericharper <complex451@gmail.com>\r\n\r\n* removed fused arg\r\n\r\nSigned-off-by: ericharper <complex451@gmail.com>\r\n\r\n* interpolate precision and sequence length in config\r\n\r\nSigned-off-by: ericharper <complex451@gmail.com>\r\n\r\n* remove trainer.precision interpolation\r\n\r\nSigned-off-by: ericharper <complex451@gmail.com>\r\n\r\n* remove nemo_experiments after prallel stage\r\n\r\nSigned-off-by: ericharper <complex451@gmail.com>\r\n\r\n* remove rm call\r\n\r\nSigned-off-by: ericharper <complex451@gmail.com>\r\n\r\nCo-authored-by: Sangkug Lym <slym@nvidia.com>\r\n\r\n* Fix the asr bucketing parsing the manifest. (#3089)\r\n\r\n* Patch LR max_step computation check (#3152)\r\n\r\n* Patch LR max_step computation check\r\n\r\nSigned-off-by: smajumdar <titu1994@gmail.com>\r\n\r\n* Perform < 0 check only\r\n\r\nSigned-off-by: smajumdar <titu1994@gmail.com>\r\n\r\n* FastPitch Notebook Bugfix (#3161)\r\n\r\n* update notebook\r\n\r\nSigned-off-by: Jason <jasoli@nvidia.com>\r\n\r\n* update test\r\n\r\nSigned-off-by: Jason <jasoli@nvidia.com>\r\n\r\n* [BugFix] Fix check for model parallel size in TP 1 case (#3162)\r\n\r\n* check model parallel size is greater than one before injection\r\n\r\nSigned-off-by: ericharper <complex451@gmail.com>\r\n\r\n* check model parallel size > 1\r\n\r\nSigned-off-by: ericharper <complex451@gmail.com>\r\n\r\n* check model parallel size is greater than one before injection\r\n\r\nSigned-off-by: ericharper <complex451@gmail.com>\r\n\r\n* check model parallel size is greater than one before injection\r\n\r\nSigned-off-by: ericharper <complex451@gmail.com>\r\n\r\n* tp 1 ckpt conv\r\n\r\nSigned-off-by: ericharper <complex451@gmail.com>\r\n\r\n* Notebook bugfixes (#3165)\r\n\r\n* zero shot intent slot notebook bug fix\r\n\r\nSigned-off-by: Virginia Adams <vadams@nvidia.com>\r\n\r\n* Added megatronBERT not support in this release message to notebook\r\n\r\nSigned-off-by: Virginia Adams <vadams@nvidia.com>\r\n\r\n* added apex backend to config\r\n\r\nSigned-off-by: Virginia Adams <vadams@nvidia.com>\r\n\r\n* Removed apex from entity linking and added 1.4.0 nemo info to warning\r\n\r\nCo-authored-by: Eric Harper <complex451@gmail.com>\r\n\r\n* add note that megatron bert is supported in r1.5.0 (#3169)\r\n\r\nSigned-off-by: ericharper <complex451@gmail.com>\r\n\r\n* Text2sparql fix 1.5.0 (#3166)\r\n\r\n* Model neural type changes\r\n\r\nSigned-off-by: MaximumEntropy <sandeep.subramanian.1@umontreal.ca>\r\n\r\n* Neural types fix\r\n\r\nSigned-off-by: MaximumEntropy <sandeep.subramanian.1@umontreal.ca>\r\n\r\n* Fix typo\r\n\r\nSigned-off-by: MaximumEntropy <sandeep.subramanian.1@umontreal.ca>\r\n\r\n* Style fixes\r\n\r\nSigned-off-by: MaximumEntropy <sandeep.subramanian.1@umontreal.ca>\r\n\r\n* Remove ipdb\r\n\r\nSigned-off-by: MaximumEntropy <sandeep.subramanian.1@umontreal.ca>\r\n\r\nCo-authored-by: Eric Harper <complex451@gmail.com>\r\n\r\n* Fix cfg issue for r1.5.0 (#3170)\r\n\r\n* fix cfg due to ptl updated\r\n\r\nSigned-off-by: fayejf <fayejf07@gmail.com>\r\n\r\n* fix\r\n\r\nSigned-off-by: fayejf <fayejf07@gmail.com>\r\n\r\n* style fix\r\n\r\nSigned-off-by: fayejf <fayejf07@gmail.com>\r\n\r\nCo-authored-by: Eric Harper <complex451@gmail.com>\r\n\r\n* update branch\r\n\r\nSigned-off-by: ericharper <complex451@gmail.com>\r\n\r\n* remove cfg\r\n\r\nSigned-off-by: ericharper <complex451@gmail.com>\r\n\r\nCo-authored-by: Jason <jasoli@nvidia.com>\r\nCo-authored-by: Sandeep Subramanian <sandeep.subramanian.1@umontreal.ca>\r\nCo-authored-by: Sangkug Lym <slym@nvidia.com>\r\nCo-authored-by: Oleksii Kuchaiev <okuchaiev@users.noreply.github.com>\r\nCo-authored-by: Somshubra Majumdar <titu1994@gmail.com>\r\nCo-authored-by: fayejf <36722593+fayejf@users.noreply.github.com>\r\nCo-authored-by: Yang Zhang <yzhang123@users.noreply.github.com>\r\nCo-authored-by: Micha Livne <michalivne@users.noreply.github.com>\r\nCo-authored-by: Micha Livne <mlivne@nvidia.com>\r\nCo-authored-by: PeganovAnton <peganoff2@mail.ru>\r\nCo-authored-by: Nithin Rao <nithinrao.koluguri@gmail.com>\r\nCo-authored-by: yaoyu-33 <54727607+yaoyu-33@users.noreply.github.com>\r\nCo-authored-by: Yu Yao <yuya@nvidia.com>\r\nCo-authored-by: Evelina <10428420+ekmb@users.noreply.github.com>\r\nCo-authored-by: Vahid Noroozi <VahidooX@users.noreply.github.com>\r\nCo-authored-by: vadam5 <78445382+vadam5@users.noreply.github.com>","tree":{"sha":"009bb0d5951336f39b8b1983655f15588e5c155c","url":"https://api.github.com/repos/tbartley94/NeMo/git/trees/009bb0d5951336f39b8b1983655f15588e5c155c"},"url":"https://api.github.com/repos/tbartley94/NeMo/git/commits/a48be1f2679198905f650e05cc93104a9dda4ec6","comment_count":0,"verification":{"verified":true,"reason":"valid","signature":"-----BEGIN PGP SIGNATURE-----\n\nwsBcBAABCAAQBQJhjgjrCRBK7hj4Ov3rIwAAbhkIAKz3SPlqB9/8SZJDv+Sb5YZU\npWVtVVOu//WeDpbkexnomaaNUOL99xWZtXFl17070HVWo7cv7Cu2LwubCwm8AXYd\ns8fOroRd52r/6sqk8xz2gUcFmt9tkQGW7nUGsY1M89jfiXWalVWV3f2iTBQF4HGL\nSD5NJxq9K7NgLEYJaHxioMXb8v+KZeHnGdsnZXeK28JiTLhh+Nzog9VGbHx+7sw1\nj/m9CNzeor9EFaYdFA6agFxiD8T/xWg7hvATcwzt95SxVV0Wok6tJVufrVgqiKs5\nZ95Qo71b62POC+5BgDQ3I1OFAh0MGVykUFnrboWYNUktdtdd3i0SvDJ5klLSoq8=\n=a8WB\n-----END PGP SIGNATURE-----\n","payload":"tree 009bb0d5951336f39b8b1983655f15588e5c155c\nparent b7a175b7b9ce7aff6f5a53012f623011cf70dca4\nauthor Eric Harper <complex451@gmail.com> 1636698347 -0700\ncommitter GitHub <noreply@github.com> 1636698347 -0700\n\nMerge r1.5.0 bugfixes to main (#3173)\n\n* update branch\r\n\r\nSigned-off-by: ericharper <complex451@gmail.com>\r\n\r\n* Always save last checkpoint on train end even if folder does not exist (#2976)\r\n\r\n* add fix for no checkpoint folder when training ends\r\n\r\nSigned-off-by: Jason <jasoli@nvidia.com>\r\n\r\n* update\r\n\r\nSigned-off-by: Jason <jasoli@nvidia.com>\r\n\r\n* fix test\r\n\r\nSigned-off-by: Jason <jasoli@nvidia.com>\r\n\r\n* fixes\r\n\r\nSigned-off-by: Jason <jasoli@nvidia.com>\r\n\r\n* typo\r\n\r\nSigned-off-by: Jason <jasoli@nvidia.com>\r\n\r\n* change check\r\n\r\nSigned-off-by: Jason <jasoli@nvidia.com>\r\n\r\n* [NLP] Add Apex import guard (#3041)\r\n\r\n* add apex import guard\r\n\r\nSigned-off-by: ericharper <complex451@gmail.com>\r\n\r\n* add apex import guard\r\n\r\nSigned-off-by: ericharper <complex451@gmail.com>\r\n\r\n* add apex import guard\r\n\r\nSigned-off-by: ericharper <complex451@gmail.com>\r\n\r\n* style\r\n\r\nSigned-off-by: ericharper <complex451@gmail.com>\r\n\r\n* remove from init add logging to constructor\r\n\r\nSigned-off-by: ericharper <complex451@gmail.com>\r\n\r\n* remove from init add logging to constructor\r\n\r\nSigned-off-by: ericharper <complex451@gmail.com>\r\n\r\n* remove import from init\r\n\r\nSigned-off-by: ericharper <complex451@gmail.com>\r\n\r\n* remove megatron bert encoder logic from NLPModel\r\n\r\nSigned-off-by: ericharper <complex451@gmail.com>\r\n\r\n* remove megatron bert from init\r\n\r\nSigned-off-by: ericharper <complex451@gmail.com>\r\n\r\n* remove megatron bert from init\r\n\r\nSigned-off-by: ericharper <complex451@gmail.com>\r\n\r\n* remove megatron bert from init\r\n\r\nSigned-off-by: ericharper <complex451@gmail.com>\r\n\r\n* remove megatron bert from init\r\n\r\nSigned-off-by: ericharper <complex451@gmail.com>\r\n\r\n* remove megatron bert from init\r\n\r\nSigned-off-by: ericharper <complex451@gmail.com>\r\n\r\n* remove megatron bert from init\r\n\r\nSigned-off-by: ericharper <complex451@gmail.com>\r\n\r\n* style\r\n\r\nSigned-off-by: ericharper <complex451@gmail.com>\r\n\r\n* Update reinstall and cherry-pick bignlp commits (#3065)\r\n\r\n* add ptl install to reinstall and update jenkins install\r\n\r\nSigned-off-by: ericharper <complex451@gmail.com>\r\n\r\n* Add a stateless timer to specify max_time per run instead of global m… (#3056)\r\n\r\n* Add a stateless timer to specify max_time per run instead of global max_time across runs\r\n\r\nSigned-off-by: MaximumEntropy <sandeep.subramanian.1@umontreal.ca>\r\n\r\n* Style fixes\r\n\r\nSigned-off-by: MaximumEntropy <sandeep.subramanian.1@umontreal.ca>\r\n\r\n* (1) reduce the validation loss within a epoch, (2) convert global-batch-based iteartion counts to micro-batch-based (#3055)\r\n\r\nCo-authored-by: Oleksii Kuchaiev <okuchaiev@users.noreply.github.com>\r\n\r\n* Timer class monitors total time (train + validation + testing) to monitor when to end training (#3061)\r\n\r\n* Check total time in train/validation to exit\r\n\r\nSigned-off-by: MaximumEntropy <sandeep.subramanian.1@umontreal.ca>\r\n\r\n* Style fixes\r\n\r\nSigned-off-by: MaximumEntropy <sandeep.subramanian.1@umontreal.ca>\r\n\r\nCo-authored-by: Oleksii Kuchaiev <okuchaiev@users.noreply.github.com>\r\n\r\n* Add PUBLICATIONS.md (#3051)\r\n\r\n* Add PUBLICATIONS.md\r\n\r\nSigned-off-by: smajumdar <titu1994@gmail.com>\r\n\r\n* Add NLP\r\n\r\nSigned-off-by: smajumdar <titu1994@gmail.com>\r\n\r\n* Update PUBLICATIONS.md\r\n\r\n* Update PUBLICATIONS.md\r\n\r\n* Fix links\r\n\r\nSigned-off-by: smajumdar <titu1994@gmail.com>\r\n\r\nCo-authored-by: Eric Harper <complex451@gmail.com>\r\n\r\n* fix uninstall\r\n\r\nSigned-off-by: ericharper <complex451@gmail.com>\r\n\r\nCo-authored-by: Sandeep Subramanian <sandeep.subramanian.1@umontreal.ca>\r\nCo-authored-by: Sangkug Lym <slym@nvidia.com>\r\nCo-authored-by: Oleksii Kuchaiev <okuchaiev@users.noreply.github.com>\r\nCo-authored-by: Somshubra Majumdar <titu1994@gmail.com>\r\n\r\n* fix File Load Error (#3069)\r\n\r\nSigned-off-by: fayejf <fayejf07@gmail.com>\r\n\r\nCo-authored-by: Eric Harper <complex451@gmail.com>\r\n\r\n* Exp manager small refactor (#3067)\r\n\r\n* Exp manager small refactor\r\n\r\nSigned-off-by: MaximumEntropy <sandeep.subramanian.1@umontreal.ca>\r\n\r\n* move super() call earlier in the function\r\n\r\nSigned-off-by: MaximumEntropy <sandeep.subramanian.1@umontreal.ca>\r\n\r\nCo-authored-by: Somshubra Majumdar <titu1994@gmail.com>\r\n\r\n* update (#3113)\r\n\r\nSigned-off-by: Jason <jasoli@nvidia.com>\r\n\r\n* Upgrade to PTL 1.5.0 (#3127)\r\n\r\n* update for ptl 1.5.0\r\n\r\nSigned-off-by: ericharper <complex451@gmail.com>\r\n\r\n* update trainer config\r\n\r\nSigned-off-by: ericharper <complex451@gmail.com>\r\n\r\n* limit cuda visible devices to the first two gpus on check for ranks CI test\r\n\r\nSigned-off-by: ericharper <complex451@gmail.com>\r\n\r\n* remove comments\r\n\r\nSigned-off-by: ericharper <complex451@gmail.com>\r\n\r\n* make datasets larger for test\r\n\r\nSigned-off-by: ericharper <complex451@gmail.com>\r\n\r\n* make datasets larger for test\r\n\r\nSigned-off-by: ericharper <complex451@gmail.com>\r\n\r\n* update compute_max_steps\r\n\r\nSigned-off-by: ericharper <complex451@gmail.com>\r\n\r\n* update compute_max_steps\r\n\r\nSigned-off-by: ericharper <complex451@gmail.com>\r\n\r\n* Update a few packages' version (#3134)\r\n\r\n* update torchaudio lower bound in tutorials\r\n\r\nSigned-off-by: fayejf <fayejf07@gmail.com>\r\n\r\n* update torchtext version in tutorials\r\n\r\nSigned-off-by: fayejf <fayejf07@gmail.com>\r\n\r\n* Revert \"update torchtext version in tutorials\"\r\n\r\nThis reverts commit 9f7f660f3b0926d3b7d6cdbb92751e0d881d65f3.\r\n\r\n* update torchtext in tutorials\r\n\r\nSigned-off-by: fayejf <fayejf07@gmail.com>\r\n\r\n* update packages version in this notebook\r\n\r\nSigned-off-by: fayejf <fayejf07@gmail.com>\r\n\r\n* update numba version in tutorial\r\n\r\nSigned-off-by: fayejf <fayejf07@gmail.com>\r\n\r\n* update requirements\r\n\r\nSigned-off-by: fayejf <fayejf07@gmail.com>\r\n\r\n* update package version in Dockerfile\r\n\r\nSigned-off-by: fayejf <fayejf07@gmail.com>\r\n\r\n* Revert \"update torchtext version in tutorials\"\r\n\r\nThis reverts commit 9f7f660f3b0926d3b7d6cdbb92751e0d881d65f3.\r\n\r\nSigned-off-by: fayejf <fayejf07@gmail.com>\r\n\r\n* added to avail models (#3044)\r\n\r\nSigned-off-by: Yang Zhang <yangzhang@nvidia.com>\r\n\r\n* 1. Fixed warmup batches when no timing is measured. (#3140)\r\n\r\nSigned-off-by: Micha Livne <mlivne@nvidia.com>\r\n\r\nCo-authored-by: Micha Livne <mlivne@nvidia.com>\r\nCo-authored-by: Yang Zhang <yzhang123@users.noreply.github.com>\r\n\r\n* Cannot unset both `source_processor` and `target_processor` for NMT model inference. (#3136)\r\n\r\n* Fix processor setting for nmt inference\r\n\r\nSigned-off-by: PeganovAnton <peganoff2@mail.ru>\r\n\r\n* Add ignore option description to argparse\r\n\r\nSigned-off-by: PeganovAnton <peganoff2@mail.ru>\r\n\r\n* Fix typo\r\n\r\nSigned-off-by: PeganovAnton <peganoff2@mail.ru>\r\n\r\nCo-authored-by: Oleksii Kuchaiev <okuchaiev@users.noreply.github.com>\r\nCo-authored-by: Sandeep Subramanian <sandeep.subramanian.1@umontreal.ca>\r\n\r\n* config link fixes (#3148)\r\n\r\nSigned-off-by: nithinraok <nithinrao.koluguri@gmail.com>\r\n\r\n* fix nemo checkpoint converter (#3149)\r\n\r\nSigned-off-by: Yu Yao <yuya@nvidia.com>\r\n\r\nCo-authored-by: Yu Yao <yuya@nvidia.com>\r\nCo-authored-by: Eric Harper <complex451@gmail.com>\r\n\r\n* link fix (#3153)\r\n\r\nSigned-off-by: ekmb <ebakhturina@nvidia.com>\r\n\r\n* remove (#3154)\r\n\r\nSigned-off-by: ekmb <ebakhturina@nvidia.com>\r\n\r\n* [BigNLP] Add CI Tests for Megatron GPT (#3124)\r\n\r\n* add pretrain CI test\r\n\r\nSigned-off-by: ericharper <complex451@gmail.com>\r\n\r\n* update test\r\n\r\nSigned-off-by: ericharper <complex451@gmail.com>\r\n\r\n* update test\r\n\r\nSigned-off-by: ericharper <complex451@gmail.com>\r\n\r\n* update test\r\n\r\nSigned-off-by: ericharper <complex451@gmail.com>\r\n\r\n* add .cpp and Makefile to python package_data\r\n\r\nSigned-off-by: ericharper <complex451@gmail.com>\r\n\r\n* check for local_rank and barrier when compiling helper\r\n\r\nSigned-off-by: ericharper <complex451@gmail.com>\r\n\r\n* check for local_rank and barrier when compiling helper\r\n\r\nSigned-off-by: ericharper <complex451@gmail.com>\r\n\r\n* remove comment\r\n\r\nSigned-off-by: ericharper <complex451@gmail.com>\r\n\r\n* remove comment\r\n\r\nSigned-off-by: ericharper <complex451@gmail.com>\r\n\r\n* add device, have jenkins test use fp16\r\n\r\nSigned-off-by: ericharper <complex451@gmail.com>\r\n\r\n* add device, have jenkins test use fp16\r\n\r\nSigned-off-by: ericharper <complex451@gmail.com>\r\n\r\n* update app_state.local_rank\r\n\r\nSigned-off-by: ericharper <complex451@gmail.com>\r\n\r\n* update config\r\n\r\nSigned-off-by: ericharper <complex451@gmail.com>\r\n\r\n* add configure gradient clipping hook\r\n\r\nSigned-off-by: ericharper <complex451@gmail.com>\r\n\r\n* style\r\n\r\nSigned-off-by: ericharper <complex451@gmail.com>\r\n\r\n* add configure gradient clipping hook\r\n\r\nSigned-off-by: ericharper <complex451@gmail.com>\r\n\r\n* add resume test\r\n\r\nSigned-off-by: ericharper <complex451@gmail.com>\r\n\r\n* add eval\r\n\r\nSigned-off-by: ericharper <complex451@gmail.com>\r\n\r\n* add eval\r\n\r\nSigned-off-by: ericharper <complex451@gmail.com>\r\n\r\n* (1) update auto-casting api, (2) simplifiy precision arguments and remove redundancy (#3142)\r\n\r\nSigned-off-by: Sangkug Lym <slym@nvidia.com>\r\n\r\n* only set jit fusion options if we are in 21.10 container\r\n\r\nSigned-off-by: ericharper <complex451@gmail.com>\r\n\r\n* update arg\r\n\r\nSigned-off-by: ericharper <complex451@gmail.com>\r\n\r\n* update nemo file for eval test\r\n\r\nSigned-off-by: ericharper <complex451@gmail.com>\r\n\r\n* remove unused import\r\n\r\nSigned-off-by: ericharper <complex451@gmail.com>\r\n\r\n* remove unused import\r\n\r\nSigned-off-by: ericharper <complex451@gmail.com>\r\n\r\n* move tests down in the jenkinsfile\r\n\r\nSigned-off-by: ericharper <complex451@gmail.com>\r\n\r\n* style\r\n\r\nSigned-off-by: ericharper <complex451@gmail.com>\r\n\r\n* removed fused arg\r\n\r\nSigned-off-by: ericharper <complex451@gmail.com>\r\n\r\n* interpolate precision and sequence length in config\r\n\r\nSigned-off-by: ericharper <complex451@gmail.com>\r\n\r\n* remove trainer.precision interpolation\r\n\r\nSigned-off-by: ericharper <complex451@gmail.com>\r\n\r\n* remove nemo_experiments after prallel stage\r\n\r\nSigned-off-by: ericharper <complex451@gmail.com>\r\n\r\n* remove rm call\r\n\r\nSigned-off-by: ericharper <complex451@gmail.com>\r\n\r\nCo-authored-by: Sangkug Lym <slym@nvidia.com>\r\n\r\n* Fix the asr bucketing parsing the manifest. (#3089)\r\n\r\n* Patch LR max_step computation check (#3152)\r\n\r\n* Patch LR max_step computation check\r\n\r\nSigned-off-by: smajumdar <titu1994@gmail.com>\r\n\r\n* Perform < 0 check only\r\n\r\nSigned-off-by: smajumdar <titu1994@gmail.com>\r\n\r\n* FastPitch Notebook Bugfix (#3161)\r\n\r\n* update notebook\r\n\r\nSigned-off-by: Jason <jasoli@nvidia.com>\r\n\r\n* update test\r\n\r\nSigned-off-by: Jason <jasoli@nvidia.com>\r\n\r\n* [BugFix] Fix check for model parallel size in TP 1 case (#3162)\r\n\r\n* check model parallel size is greater than one before injection\r\n\r\nSigned-off-by: ericharper <complex451@gmail.com>\r\n\r\n* check model parallel size > 1\r\n\r\nSigned-off-by: ericharper <complex451@gmail.com>\r\n\r\n* check model parallel size is greater than one before injection\r\n\r\nSigned-off-by: ericharper <complex451@gmail.com>\r\n\r\n* check model parallel size is greater than one before injection\r\n\r\nSigned-off-by: ericharper <complex451@gmail.com>\r\n\r\n* tp 1 ckpt conv\r\n\r\nSigned-off-by: ericharper <complex451@gmail.com>\r\n\r\n* Notebook bugfixes (#3165)\r\n\r\n* zero shot intent slot notebook bug fix\r\n\r\nSigned-off-by: Virginia Adams <vadams@nvidia.com>\r\n\r\n* Added megatronBERT not support in this release message to notebook\r\n\r\nSigned-off-by: Virginia Adams <vadams@nvidia.com>\r\n\r\n* added apex backend to config\r\n\r\nSigned-off-by: Virginia Adams <vadams@nvidia.com>\r\n\r\n* Removed apex from entity linking and added 1.4.0 nemo info to warning\r\n\r\nCo-authored-by: Eric Harper <complex451@gmail.com>\r\n\r\n* add note that megatron bert is supported in r1.5.0 (#3169)\r\n\r\nSigned-off-by: ericharper <complex451@gmail.com>\r\n\r\n* Text2sparql fix 1.5.0 (#3166)\r\n\r\n* Model neural type changes\r\n\r\nSigned-off-by: MaximumEntropy <sandeep.subramanian.1@umontreal.ca>\r\n\r\n* Neural types fix\r\n\r\nSigned-off-by: MaximumEntropy <sandeep.subramanian.1@umontreal.ca>\r\n\r\n* Fix typo\r\n\r\nSigned-off-by: MaximumEntropy <sandeep.subramanian.1@umontreal.ca>\r\n\r\n* Style fixes\r\n\r\nSigned-off-by: MaximumEntropy <sandeep.subramanian.1@umontreal.ca>\r\n\r\n* Remove ipdb\r\n\r\nSigned-off-by: MaximumEntropy <sandeep.subramanian.1@umontreal.ca>\r\n\r\nCo-authored-by: Eric Harper <complex451@gmail.com>\r\n\r\n* Fix cfg issue for r1.5.0 (#3170)\r\n\r\n* fix cfg due to ptl updated\r\n\r\nSigned-off-by: fayejf <fayejf07@gmail.com>\r\n\r\n* fix\r\n\r\nSigned-off-by: fayejf <fayejf07@gmail.com>\r\n\r\n* style fix\r\n\r\nSigned-off-by: fayejf <fayejf07@gmail.com>\r\n\r\nCo-authored-by: Eric Harper <complex451@gmail.com>\r\n\r\n* update branch\r\n\r\nSigned-off-by: ericharper <complex451@gmail.com>\r\n\r\n* remove cfg\r\n\r\nSigned-off-by: ericharper <complex451@gmail.com>\r\n\r\nCo-authored-by: Jason <jasoli@nvidia.com>\r\nCo-authored-by: Sandeep Subramanian <sandeep.subramanian.1@umontreal.ca>\r\nCo-authored-by: Sangkug Lym <slym@nvidia.com>\r\nCo-authored-by: Oleksii Kuchaiev <okuchaiev@users.noreply.github.com>\r\nCo-authored-by: Somshubra Majumdar <titu1994@gmail.com>\r\nCo-authored-by: fayejf <36722593+fayejf@users.noreply.github.com>\r\nCo-authored-by: Yang Zhang <yzhang123@users.noreply.github.com>\r\nCo-authored-by: Micha Livne <michalivne@users.noreply.github.com>\r\nCo-authored-by: Micha Livne <mlivne@nvidia.com>\r\nCo-authored-by: PeganovAnton <peganoff2@mail.ru>\r\nCo-authored-by: Nithin Rao <nithinrao.koluguri@gmail.com>\r\nCo-authored-by: yaoyu-33 <54727607+yaoyu-33@users.noreply.github.com>\r\nCo-authored-by: Yu Yao <yuya@nvidia.com>\r\nCo-authored-by: Evelina <10428420+ekmb@users.noreply.github.com>\r\nCo-authored-by: Vahid Noroozi <VahidooX@users.noreply.github.com>\r\nCo-authored-by: vadam5 <78445382+vadam5@users.noreply.github.com>"}},"url":"https://api.github.com/repos/tbartley94/NeMo/commits/a48be1f2679198905f650e05cc93104a9dda4ec6","html_url":"https://github.com/tbartley94/NeMo/commit/a48be1f2679198905f650e05cc93104a9dda4ec6","comments_url":"https://api.github.com/repos/tbartley94/NeMo/commits/a48be1f2679198905f650e05cc93104a9dda4ec6/comments","author":{"login":"ericharper","id":11999610,"node_id":"MDQ6VXNlcjExOTk5NjEw","avatar_url":"https://avatars.githubusercontent.com/u/11999610?v=4","gravatar_id":"","url":"https://api.github.com/users/ericharper","html_url":"https://github.com/ericharper","followers_url":"https://api.github.com/users/ericharper/followers","following_url":"https://api.github.com/users/ericharper/following{/other_user}","gists_url":"https://api.github.com/users/ericharper/gists{/gist_id}","starred_url":"https://api.github.com/users/ericharper/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/ericharper/subscriptions","organizations_url":"https://api.github.com/users/ericharper/orgs","repos_url":"https://api.github.com/users/ericharper/repos","events_url":"https://api.github.com/users/ericharper/events{/privacy}","received_events_url":"https://api.github.com/users/ericharper/received_events","type":"User","site_admin":false},"committer":{"login":"web-flow","id":19864447,"node_id":"MDQ6VXNlcjE5ODY0NDQ3","avatar_url":"https://avatars.githubusercontent.com/u/19864447?v=4","gravatar_id":"","url":"https://api.github.com/users/web-flow","html_url":"https://github.com/web-flow","followers_url":"https://api.github.com/users/web-flow/followers","following_url":"https://api.github.com/users/web-flow/following{/other_user}","gists_url":"https://api.github.com/users/web-flow/gists{/gist_id}","starred_url":"https://api.github.com/users/web-flow/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/web-flow/subscriptions","organizations_url":"https://api.github.com/users/web-flow/orgs","repos_url":"https://api.github.com/users/web-flow/repos","events_url":"https://api.github.com/users/web-flow/events{/privacy}","received_events_url":"https://api.github.com/users/web-flow/received_events","type":"User","site_admin":false},"parents":[{"sha":"b7a175b7b9ce7aff6f5a53012f623011cf70dca4","url":"https://api.github.com/repos/tbartley94/NeMo/commits/b7a175b7b9ce7aff6f5a53012f623011cf70dca4","html_url":"https://github.com/tbartley94/NeMo/commit/b7a175b7b9ce7aff6f5a53012f623011cf70dca4"}]}]